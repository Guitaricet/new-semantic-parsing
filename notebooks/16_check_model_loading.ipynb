{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_path = \"/Users/vladislavlialin/Documents/new-semantic-parsing/tests/test_cli/train_lihgtning_output/_ckpt_epoch_0.ckpt\"\n",
    "hf_path = \"/Users/vladislavlialin/Documents/new-semantic-parsing/tests/test_cli/train_lihgtning_output/pytorch_model.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-07 23:50:51 | ERROR | wandb.jupyter | Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mguitaricet\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.12<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">sunny-wood-2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/guitaricet/new-semantic-parsing-notebooks\" target=\"_blank\">https://wandb.ai/guitaricet/new-semantic-parsing-notebooks</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/guitaricet/new-semantic-parsing-notebooks/runs/1fm1xfi6\" target=\"_blank\">https://wandb.ai/guitaricet/new-semantic-parsing-notebooks/runs/1fm1xfi6</a><br/>\n",
       "                Run data is saved locally in <code>/Users/vladislavlialin/Documents/new-semantic-parsing/notebooks/wandb/run-20210107_235052-1fm1xfi6</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gradients'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
       "\u001b[0;31mFile:\u001b[0m      ~/miniconda3/envs/nsp/lib/python3.8/site-packages/wandb/sdk/wandb_run.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?run.watch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(190, 190)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl_checkpoint = torch.load(pl_path)[\"state_dict\"]\n",
    "hf_checkpoint = torch.load(hf_path)\n",
    "\n",
    "len(pl_checkpoint), len(hf_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Config.update of {}>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.config.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['model.encoder.embeddings.word_embeddings.weight', 'model.encoder.embeddings.position_embeddings.weight', 'model.encoder.embeddings.token_type_embeddings.weight', 'model.encoder.embeddings.LayerNorm.weight', 'model.encoder.embeddings.LayerNorm.bias', 'model.encoder.encoder.layer.0.attention.self.query.weight', 'model.encoder.encoder.layer.0.attention.self.query.bias', 'model.encoder.encoder.layer.0.attention.self.key.weight', 'model.encoder.encoder.layer.0.attention.self.key.bias', 'model.encoder.encoder.layer.0.attention.self.value.weight', 'model.encoder.encoder.layer.0.attention.self.value.bias', 'model.encoder.encoder.layer.0.attention.output.dense.weight', 'model.encoder.encoder.layer.0.attention.output.dense.bias', 'model.encoder.encoder.layer.0.attention.output.LayerNorm.weight', 'model.encoder.encoder.layer.0.attention.output.LayerNorm.bias', 'model.encoder.encoder.layer.0.intermediate.dense.weight', 'model.encoder.encoder.layer.0.intermediate.dense.bias', 'model.encoder.encoder.layer.0.output.dense.weight', 'model.encoder.encoder.layer.0.output.dense.bias', 'model.encoder.encoder.layer.0.output.LayerNorm.weight', 'model.encoder.encoder.layer.0.output.LayerNorm.bias', 'model.encoder.pooler.dense.weight', 'model.encoder.pooler.dense.bias', 'model.decoder.embeddings.word_embeddings.weight', 'model.decoder.embeddings.position_embeddings.weight', 'model.decoder.embeddings.token_type_embeddings.weight', 'model.decoder.embeddings.LayerNorm.weight', 'model.decoder.embeddings.LayerNorm.bias', 'model.decoder.encoder.layer.0.attention.self.query.weight', 'model.decoder.encoder.layer.0.attention.self.query.bias', 'model.decoder.encoder.layer.0.attention.self.key.weight', 'model.decoder.encoder.layer.0.attention.self.key.bias', 'model.decoder.encoder.layer.0.attention.self.value.weight', 'model.decoder.encoder.layer.0.attention.self.value.bias', 'model.decoder.encoder.layer.0.attention.output.dense.weight', 'model.decoder.encoder.layer.0.attention.output.dense.bias', 'model.decoder.encoder.layer.0.attention.output.LayerNorm.weight', 'model.decoder.encoder.layer.0.attention.output.LayerNorm.bias', 'model.decoder.encoder.layer.0.crossattention.self.query.weight', 'model.decoder.encoder.layer.0.crossattention.self.query.bias', 'model.decoder.encoder.layer.0.crossattention.self.key.weight', 'model.decoder.encoder.layer.0.crossattention.self.key.bias', 'model.decoder.encoder.layer.0.crossattention.self.value.weight', 'model.decoder.encoder.layer.0.crossattention.self.value.bias', 'model.decoder.encoder.layer.0.crossattention.output.dense.weight', 'model.decoder.encoder.layer.0.crossattention.output.dense.bias', 'model.decoder.encoder.layer.0.crossattention.output.LayerNorm.weight', 'model.decoder.encoder.layer.0.crossattention.output.LayerNorm.bias', 'model.decoder.encoder.layer.0.intermediate.dense.weight', 'model.decoder.encoder.layer.0.intermediate.dense.bias', 'model.decoder.encoder.layer.0.output.dense.weight', 'model.decoder.encoder.layer.0.output.dense.bias', 'model.decoder.encoder.layer.0.output.LayerNorm.weight', 'model.decoder.encoder.layer.0.output.LayerNorm.bias', 'model.decoder.pooler.dense.weight', 'model.decoder.pooler.dense.bias', 'model.lm_head.bias', 'model.lm_head.transform.dense.weight', 'model.lm_head.transform.dense.bias', 'model.lm_head.transform.LayerNorm.weight', 'model.lm_head.transform.LayerNorm.bias', 'model.lm_head.decoder.weight', 'model.lm_head.decoder.bias', 'model.decoder_q_proj.weight', 'model.grad_squared.encoder_embeddings_word_embeddings_weight', 'model.grad_squared.encoder_embeddings_position_embeddings_weight', 'model.grad_squared.encoder_embeddings_token_type_embeddings_weight', 'model.grad_squared.encoder_embeddings_LayerNorm_weight', 'model.grad_squared.encoder_embeddings_LayerNorm_bias', 'model.grad_squared.encoder_encoder_layer_0_attention_self_query_weight', 'model.grad_squared.encoder_encoder_layer_0_attention_self_query_bias', 'model.grad_squared.encoder_encoder_layer_0_attention_self_key_weight', 'model.grad_squared.encoder_encoder_layer_0_attention_self_key_bias', 'model.grad_squared.encoder_encoder_layer_0_attention_self_value_weight', 'model.grad_squared.encoder_encoder_layer_0_attention_self_value_bias', 'model.grad_squared.encoder_encoder_layer_0_attention_output_dense_weight', 'model.grad_squared.encoder_encoder_layer_0_attention_output_dense_bias', 'model.grad_squared.encoder_encoder_layer_0_attention_output_LayerNorm_weight', 'model.grad_squared.encoder_encoder_layer_0_attention_output_LayerNorm_bias', 'model.grad_squared.encoder_encoder_layer_0_intermediate_dense_weight', 'model.grad_squared.encoder_encoder_layer_0_intermediate_dense_bias', 'model.grad_squared.encoder_encoder_layer_0_output_dense_weight', 'model.grad_squared.encoder_encoder_layer_0_output_dense_bias', 'model.grad_squared.encoder_encoder_layer_0_output_LayerNorm_weight', 'model.grad_squared.encoder_encoder_layer_0_output_LayerNorm_bias', 'model.grad_squared.encoder_pooler_dense_weight', 'model.grad_squared.encoder_pooler_dense_bias', 'model.grad_squared.decoder_embeddings_word_embeddings_weight', 'model.grad_squared.decoder_embeddings_position_embeddings_weight', 'model.grad_squared.decoder_embeddings_token_type_embeddings_weight', 'model.grad_squared.decoder_embeddings_LayerNorm_weight', 'model.grad_squared.decoder_embeddings_LayerNorm_bias', 'model.grad_squared.decoder_encoder_layer_0_attention_self_query_weight', 'model.grad_squared.decoder_encoder_layer_0_attention_self_query_bias', 'model.grad_squared.decoder_encoder_layer_0_attention_self_key_weight', 'model.grad_squared.decoder_encoder_layer_0_attention_self_key_bias', 'model.grad_squared.decoder_encoder_layer_0_attention_self_value_weight', 'model.grad_squared.decoder_encoder_layer_0_attention_self_value_bias', 'model.grad_squared.decoder_encoder_layer_0_attention_output_dense_weight', 'model.grad_squared.decoder_encoder_layer_0_attention_output_dense_bias', 'model.grad_squared.decoder_encoder_layer_0_attention_output_LayerNorm_weight', 'model.grad_squared.decoder_encoder_layer_0_attention_output_LayerNorm_bias', 'model.grad_squared.decoder_encoder_layer_0_crossattention_self_query_weight', 'model.grad_squared.decoder_encoder_layer_0_crossattention_self_query_bias', 'model.grad_squared.decoder_encoder_layer_0_crossattention_self_key_weight', 'model.grad_squared.decoder_encoder_layer_0_crossattention_self_key_bias', 'model.grad_squared.decoder_encoder_layer_0_crossattention_self_value_weight', 'model.grad_squared.decoder_encoder_layer_0_crossattention_self_value_bias', 'model.grad_squared.decoder_encoder_layer_0_crossattention_output_dense_weight', 'model.grad_squared.decoder_encoder_layer_0_crossattention_output_dense_bias', 'model.grad_squared.decoder_encoder_layer_0_crossattention_output_LayerNorm_weight', 'model.grad_squared.decoder_encoder_layer_0_crossattention_output_LayerNorm_bias', 'model.grad_squared.decoder_encoder_layer_0_intermediate_dense_weight', 'model.grad_squared.decoder_encoder_layer_0_intermediate_dense_bias', 'model.grad_squared.decoder_encoder_layer_0_output_dense_weight', 'model.grad_squared.decoder_encoder_layer_0_output_dense_bias', 'model.grad_squared.decoder_encoder_layer_0_output_LayerNorm_weight', 'model.grad_squared.decoder_encoder_layer_0_output_LayerNorm_bias', 'model.grad_squared.decoder_pooler_dense_weight', 'model.grad_squared.decoder_pooler_dense_bias', 'model.grad_squared.lm_head_bias', 'model.grad_squared.lm_head_transform_dense_weight', 'model.grad_squared.lm_head_transform_dense_bias', 'model.grad_squared.lm_head_transform_LayerNorm_weight', 'model.grad_squared.lm_head_transform_LayerNorm_bias', 'model.grad_squared.lm_head_decoder_weight', 'model.grad_squared.decoder_q_proj_weight', 'model.initial_params.encoder_embeddings_word_embeddings_weight', 'model.initial_params.encoder_embeddings_position_embeddings_weight', 'model.initial_params.encoder_embeddings_token_type_embeddings_weight', 'model.initial_params.encoder_embeddings_LayerNorm_weight', 'model.initial_params.encoder_embeddings_LayerNorm_bias', 'model.initial_params.encoder_encoder_layer_0_attention_self_query_weight', 'model.initial_params.encoder_encoder_layer_0_attention_self_query_bias', 'model.initial_params.encoder_encoder_layer_0_attention_self_key_weight', 'model.initial_params.encoder_encoder_layer_0_attention_self_key_bias', 'model.initial_params.encoder_encoder_layer_0_attention_self_value_weight', 'model.initial_params.encoder_encoder_layer_0_attention_self_value_bias', 'model.initial_params.encoder_encoder_layer_0_attention_output_dense_weight', 'model.initial_params.encoder_encoder_layer_0_attention_output_dense_bias', 'model.initial_params.encoder_encoder_layer_0_attention_output_LayerNorm_weight', 'model.initial_params.encoder_encoder_layer_0_attention_output_LayerNorm_bias', 'model.initial_params.encoder_encoder_layer_0_intermediate_dense_weight', 'model.initial_params.encoder_encoder_layer_0_intermediate_dense_bias', 'model.initial_params.encoder_encoder_layer_0_output_dense_weight', 'model.initial_params.encoder_encoder_layer_0_output_dense_bias', 'model.initial_params.encoder_encoder_layer_0_output_LayerNorm_weight', 'model.initial_params.encoder_encoder_layer_0_output_LayerNorm_bias', 'model.initial_params.encoder_pooler_dense_weight', 'model.initial_params.encoder_pooler_dense_bias', 'model.initial_params.decoder_embeddings_word_embeddings_weight', 'model.initial_params.decoder_embeddings_position_embeddings_weight', 'model.initial_params.decoder_embeddings_token_type_embeddings_weight', 'model.initial_params.decoder_embeddings_LayerNorm_weight', 'model.initial_params.decoder_embeddings_LayerNorm_bias', 'model.initial_params.decoder_encoder_layer_0_attention_self_query_weight', 'model.initial_params.decoder_encoder_layer_0_attention_self_query_bias', 'model.initial_params.decoder_encoder_layer_0_attention_self_key_weight', 'model.initial_params.decoder_encoder_layer_0_attention_self_key_bias', 'model.initial_params.decoder_encoder_layer_0_attention_self_value_weight', 'model.initial_params.decoder_encoder_layer_0_attention_self_value_bias', 'model.initial_params.decoder_encoder_layer_0_attention_output_dense_weight', 'model.initial_params.decoder_encoder_layer_0_attention_output_dense_bias', 'model.initial_params.decoder_encoder_layer_0_attention_output_LayerNorm_weight', 'model.initial_params.decoder_encoder_layer_0_attention_output_LayerNorm_bias', 'model.initial_params.decoder_encoder_layer_0_crossattention_self_query_weight', 'model.initial_params.decoder_encoder_layer_0_crossattention_self_query_bias', 'model.initial_params.decoder_encoder_layer_0_crossattention_self_key_weight', 'model.initial_params.decoder_encoder_layer_0_crossattention_self_key_bias', 'model.initial_params.decoder_encoder_layer_0_crossattention_self_value_weight', 'model.initial_params.decoder_encoder_layer_0_crossattention_self_value_bias', 'model.initial_params.decoder_encoder_layer_0_crossattention_output_dense_weight', 'model.initial_params.decoder_encoder_layer_0_crossattention_output_dense_bias', 'model.initial_params.decoder_encoder_layer_0_crossattention_output_LayerNorm_weight', 'model.initial_params.decoder_encoder_layer_0_crossattention_output_LayerNorm_bias', 'model.initial_params.decoder_encoder_layer_0_intermediate_dense_weight', 'model.initial_params.decoder_encoder_layer_0_intermediate_dense_bias', 'model.initial_params.decoder_encoder_layer_0_output_dense_weight', 'model.initial_params.decoder_encoder_layer_0_output_dense_bias', 'model.initial_params.decoder_encoder_layer_0_output_LayerNorm_weight', 'model.initial_params.decoder_encoder_layer_0_output_LayerNorm_bias', 'model.initial_params.decoder_pooler_dense_weight', 'model.initial_params.decoder_pooler_dense_bias', 'model.initial_params.lm_head_bias', 'model.initial_params.lm_head_transform_dense_weight', 'model.initial_params.lm_head_transform_dense_bias', 'model.initial_params.lm_head_transform_LayerNorm_weight', 'model.initial_params.lm_head_transform_LayerNorm_bias', 'model.initial_params.lm_head_decoder_weight', 'model.initial_params.decoder_q_proj_weight'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl_checkpoint.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['encoder.embeddings.word_embeddings.weight', 'encoder.embeddings.position_embeddings.weight', 'encoder.embeddings.token_type_embeddings.weight', 'encoder.embeddings.LayerNorm.weight', 'encoder.embeddings.LayerNorm.bias', 'encoder.encoder.layer.0.attention.self.query.weight', 'encoder.encoder.layer.0.attention.self.query.bias', 'encoder.encoder.layer.0.attention.self.key.weight', 'encoder.encoder.layer.0.attention.self.key.bias', 'encoder.encoder.layer.0.attention.self.value.weight', 'encoder.encoder.layer.0.attention.self.value.bias', 'encoder.encoder.layer.0.attention.output.dense.weight', 'encoder.encoder.layer.0.attention.output.dense.bias', 'encoder.encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.encoder.layer.0.intermediate.dense.weight', 'encoder.encoder.layer.0.intermediate.dense.bias', 'encoder.encoder.layer.0.output.dense.weight', 'encoder.encoder.layer.0.output.dense.bias', 'encoder.encoder.layer.0.output.LayerNorm.weight', 'encoder.encoder.layer.0.output.LayerNorm.bias', 'encoder.pooler.dense.weight', 'encoder.pooler.dense.bias', 'decoder.embeddings.word_embeddings.weight', 'decoder.embeddings.position_embeddings.weight', 'decoder.embeddings.token_type_embeddings.weight', 'decoder.embeddings.LayerNorm.weight', 'decoder.embeddings.LayerNorm.bias', 'decoder.encoder.layer.0.attention.self.query.weight', 'decoder.encoder.layer.0.attention.self.query.bias', 'decoder.encoder.layer.0.attention.self.key.weight', 'decoder.encoder.layer.0.attention.self.key.bias', 'decoder.encoder.layer.0.attention.self.value.weight', 'decoder.encoder.layer.0.attention.self.value.bias', 'decoder.encoder.layer.0.attention.output.dense.weight', 'decoder.encoder.layer.0.attention.output.dense.bias', 'decoder.encoder.layer.0.attention.output.LayerNorm.weight', 'decoder.encoder.layer.0.attention.output.LayerNorm.bias', 'decoder.encoder.layer.0.crossattention.self.query.weight', 'decoder.encoder.layer.0.crossattention.self.query.bias', 'decoder.encoder.layer.0.crossattention.self.key.weight', 'decoder.encoder.layer.0.crossattention.self.key.bias', 'decoder.encoder.layer.0.crossattention.self.value.weight', 'decoder.encoder.layer.0.crossattention.self.value.bias', 'decoder.encoder.layer.0.crossattention.output.dense.weight', 'decoder.encoder.layer.0.crossattention.output.dense.bias', 'decoder.encoder.layer.0.crossattention.output.LayerNorm.weight', 'decoder.encoder.layer.0.crossattention.output.LayerNorm.bias', 'decoder.encoder.layer.0.intermediate.dense.weight', 'decoder.encoder.layer.0.intermediate.dense.bias', 'decoder.encoder.layer.0.output.dense.weight', 'decoder.encoder.layer.0.output.dense.bias', 'decoder.encoder.layer.0.output.LayerNorm.weight', 'decoder.encoder.layer.0.output.LayerNorm.bias', 'decoder.pooler.dense.weight', 'decoder.pooler.dense.bias', 'lm_head.bias', 'lm_head.transform.dense.weight', 'lm_head.transform.dense.bias', 'lm_head.transform.LayerNorm.weight', 'lm_head.transform.LayerNorm.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'decoder_q_proj.weight', 'grad_squared.encoder_embeddings_word_embeddings_weight', 'grad_squared.encoder_embeddings_position_embeddings_weight', 'grad_squared.encoder_embeddings_token_type_embeddings_weight', 'grad_squared.encoder_embeddings_LayerNorm_weight', 'grad_squared.encoder_embeddings_LayerNorm_bias', 'grad_squared.encoder_encoder_layer_0_attention_self_query_weight', 'grad_squared.encoder_encoder_layer_0_attention_self_query_bias', 'grad_squared.encoder_encoder_layer_0_attention_self_key_weight', 'grad_squared.encoder_encoder_layer_0_attention_self_key_bias', 'grad_squared.encoder_encoder_layer_0_attention_self_value_weight', 'grad_squared.encoder_encoder_layer_0_attention_self_value_bias', 'grad_squared.encoder_encoder_layer_0_attention_output_dense_weight', 'grad_squared.encoder_encoder_layer_0_attention_output_dense_bias', 'grad_squared.encoder_encoder_layer_0_attention_output_LayerNorm_weight', 'grad_squared.encoder_encoder_layer_0_attention_output_LayerNorm_bias', 'grad_squared.encoder_encoder_layer_0_intermediate_dense_weight', 'grad_squared.encoder_encoder_layer_0_intermediate_dense_bias', 'grad_squared.encoder_encoder_layer_0_output_dense_weight', 'grad_squared.encoder_encoder_layer_0_output_dense_bias', 'grad_squared.encoder_encoder_layer_0_output_LayerNorm_weight', 'grad_squared.encoder_encoder_layer_0_output_LayerNorm_bias', 'grad_squared.encoder_pooler_dense_weight', 'grad_squared.encoder_pooler_dense_bias', 'grad_squared.decoder_embeddings_word_embeddings_weight', 'grad_squared.decoder_embeddings_position_embeddings_weight', 'grad_squared.decoder_embeddings_token_type_embeddings_weight', 'grad_squared.decoder_embeddings_LayerNorm_weight', 'grad_squared.decoder_embeddings_LayerNorm_bias', 'grad_squared.decoder_encoder_layer_0_attention_self_query_weight', 'grad_squared.decoder_encoder_layer_0_attention_self_query_bias', 'grad_squared.decoder_encoder_layer_0_attention_self_key_weight', 'grad_squared.decoder_encoder_layer_0_attention_self_key_bias', 'grad_squared.decoder_encoder_layer_0_attention_self_value_weight', 'grad_squared.decoder_encoder_layer_0_attention_self_value_bias', 'grad_squared.decoder_encoder_layer_0_attention_output_dense_weight', 'grad_squared.decoder_encoder_layer_0_attention_output_dense_bias', 'grad_squared.decoder_encoder_layer_0_attention_output_LayerNorm_weight', 'grad_squared.decoder_encoder_layer_0_attention_output_LayerNorm_bias', 'grad_squared.decoder_encoder_layer_0_crossattention_self_query_weight', 'grad_squared.decoder_encoder_layer_0_crossattention_self_query_bias', 'grad_squared.decoder_encoder_layer_0_crossattention_self_key_weight', 'grad_squared.decoder_encoder_layer_0_crossattention_self_key_bias', 'grad_squared.decoder_encoder_layer_0_crossattention_self_value_weight', 'grad_squared.decoder_encoder_layer_0_crossattention_self_value_bias', 'grad_squared.decoder_encoder_layer_0_crossattention_output_dense_weight', 'grad_squared.decoder_encoder_layer_0_crossattention_output_dense_bias', 'grad_squared.decoder_encoder_layer_0_crossattention_output_LayerNorm_weight', 'grad_squared.decoder_encoder_layer_0_crossattention_output_LayerNorm_bias', 'grad_squared.decoder_encoder_layer_0_intermediate_dense_weight', 'grad_squared.decoder_encoder_layer_0_intermediate_dense_bias', 'grad_squared.decoder_encoder_layer_0_output_dense_weight', 'grad_squared.decoder_encoder_layer_0_output_dense_bias', 'grad_squared.decoder_encoder_layer_0_output_LayerNorm_weight', 'grad_squared.decoder_encoder_layer_0_output_LayerNorm_bias', 'grad_squared.decoder_pooler_dense_weight', 'grad_squared.decoder_pooler_dense_bias', 'grad_squared.lm_head_bias', 'grad_squared.lm_head_transform_dense_weight', 'grad_squared.lm_head_transform_dense_bias', 'grad_squared.lm_head_transform_LayerNorm_weight', 'grad_squared.lm_head_transform_LayerNorm_bias', 'grad_squared.lm_head_decoder_weight', 'grad_squared.decoder_q_proj_weight', 'initial_params.encoder_embeddings_word_embeddings_weight', 'initial_params.encoder_embeddings_position_embeddings_weight', 'initial_params.encoder_embeddings_token_type_embeddings_weight', 'initial_params.encoder_embeddings_LayerNorm_weight', 'initial_params.encoder_embeddings_LayerNorm_bias', 'initial_params.encoder_encoder_layer_0_attention_self_query_weight', 'initial_params.encoder_encoder_layer_0_attention_self_query_bias', 'initial_params.encoder_encoder_layer_0_attention_self_key_weight', 'initial_params.encoder_encoder_layer_0_attention_self_key_bias', 'initial_params.encoder_encoder_layer_0_attention_self_value_weight', 'initial_params.encoder_encoder_layer_0_attention_self_value_bias', 'initial_params.encoder_encoder_layer_0_attention_output_dense_weight', 'initial_params.encoder_encoder_layer_0_attention_output_dense_bias', 'initial_params.encoder_encoder_layer_0_attention_output_LayerNorm_weight', 'initial_params.encoder_encoder_layer_0_attention_output_LayerNorm_bias', 'initial_params.encoder_encoder_layer_0_intermediate_dense_weight', 'initial_params.encoder_encoder_layer_0_intermediate_dense_bias', 'initial_params.encoder_encoder_layer_0_output_dense_weight', 'initial_params.encoder_encoder_layer_0_output_dense_bias', 'initial_params.encoder_encoder_layer_0_output_LayerNorm_weight', 'initial_params.encoder_encoder_layer_0_output_LayerNorm_bias', 'initial_params.encoder_pooler_dense_weight', 'initial_params.encoder_pooler_dense_bias', 'initial_params.decoder_embeddings_word_embeddings_weight', 'initial_params.decoder_embeddings_position_embeddings_weight', 'initial_params.decoder_embeddings_token_type_embeddings_weight', 'initial_params.decoder_embeddings_LayerNorm_weight', 'initial_params.decoder_embeddings_LayerNorm_bias', 'initial_params.decoder_encoder_layer_0_attention_self_query_weight', 'initial_params.decoder_encoder_layer_0_attention_self_query_bias', 'initial_params.decoder_encoder_layer_0_attention_self_key_weight', 'initial_params.decoder_encoder_layer_0_attention_self_key_bias', 'initial_params.decoder_encoder_layer_0_attention_self_value_weight', 'initial_params.decoder_encoder_layer_0_attention_self_value_bias', 'initial_params.decoder_encoder_layer_0_attention_output_dense_weight', 'initial_params.decoder_encoder_layer_0_attention_output_dense_bias', 'initial_params.decoder_encoder_layer_0_attention_output_LayerNorm_weight', 'initial_params.decoder_encoder_layer_0_attention_output_LayerNorm_bias', 'initial_params.decoder_encoder_layer_0_crossattention_self_query_weight', 'initial_params.decoder_encoder_layer_0_crossattention_self_query_bias', 'initial_params.decoder_encoder_layer_0_crossattention_self_key_weight', 'initial_params.decoder_encoder_layer_0_crossattention_self_key_bias', 'initial_params.decoder_encoder_layer_0_crossattention_self_value_weight', 'initial_params.decoder_encoder_layer_0_crossattention_self_value_bias', 'initial_params.decoder_encoder_layer_0_crossattention_output_dense_weight', 'initial_params.decoder_encoder_layer_0_crossattention_output_dense_bias', 'initial_params.decoder_encoder_layer_0_crossattention_output_LayerNorm_weight', 'initial_params.decoder_encoder_layer_0_crossattention_output_LayerNorm_bias', 'initial_params.decoder_encoder_layer_0_intermediate_dense_weight', 'initial_params.decoder_encoder_layer_0_intermediate_dense_bias', 'initial_params.decoder_encoder_layer_0_output_dense_weight', 'initial_params.decoder_encoder_layer_0_output_dense_bias', 'initial_params.decoder_encoder_layer_0_output_LayerNorm_weight', 'initial_params.decoder_encoder_layer_0_output_LayerNorm_bias', 'initial_params.decoder_pooler_dense_weight', 'initial_params.decoder_pooler_dense_bias', 'initial_params.lm_head_bias', 'initial_params.lm_head_transform_dense_weight', 'initial_params.lm_head_transform_dense_bias', 'initial_params.lm_head_transform_LayerNorm_weight', 'initial_params.lm_head_transform_LayerNorm_bias', 'initial_params.lm_head_decoder_weight', 'initial_params.decoder_q_proj_weight'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_checkpoint.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.all(pl_checkpoint[\"model.encoder.encoder.layer.0.attention.self.value.weight\"] == hf_checkpoint[\"encoder.encoder.layer.0.attention.self.value.weight\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in hf_checkpoint.keys():\n",
    "    hf_weight = hf_checkpoint[key]\n",
    "    pl_weight = pl_checkpoint[\"model.\" + key]\n",
    "    \n",
    "    if not torch.all(hf_weight == pl_weight):\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nsp",
   "language": "python",
   "name": "nsp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
