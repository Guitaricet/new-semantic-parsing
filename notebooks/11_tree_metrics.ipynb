{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pprint import pprint\n",
    "from operator import add\n",
    "from functools import reduce\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from new_semantic_parsing import TopSchemaTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "LBR = '['\n",
    "RBR = ']'\n",
    "IN = 'IN:'\n",
    "SL = 'SL:'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tree:\n",
    "    def __init__(self, entity, subtrees: List = None):\n",
    "        self.entity = entity\n",
    "        self.subtrees = subtrees\n",
    "        if subtrees is None:\n",
    "            self.subtrees = []\n",
    "\n",
    "        # for per-class metrics\n",
    "        self._counts = Counter([entity])\n",
    "        self._len = 1\n",
    "\n",
    "        if len(self.subtrees) > 0:\n",
    "            self._len += sum(map(len, self.subtrees))\n",
    "            self._counts += reduce(add, (s._counts for s in self.subtrees))\n",
    "\n",
    "        self._dict_repr = {self.entity: [s._dict_repr for s in self.subtrees]}\n",
    "\n",
    "    def __repr__(self):\n",
    "        return repr(self._dict_repr)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, dict):\n",
    "            return self._dict_repr == other\n",
    "        if isinstance(other, Tree):\n",
    "            return self._dict_repr == other._dict_repr\n",
    "        raise ValueError(type(other))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self._len\n",
    "    \n",
    "    @property\n",
    "    def counts(self):\n",
    "        return self._counts\n",
    "\n",
    "    @classmethod\n",
    "    def from_tokens(cls, tokens, return_index=False):\n",
    "        \"\"\"Builds a parsing tree for labeled bracketing score computation.\n",
    "\n",
    "        Args:\n",
    "            tokens: list of tokens\n",
    "            return_index: used in recursion to provide toke index\n",
    "\n",
    "        Returns:\n",
    "            tuple of size two: Tree, last_index\n",
    "        \"\"\"\n",
    "        # every tree should start with\n",
    "        # [ ENTITY_TYPE: ENTITY\n",
    "        if len(tokens) < 3 or tokens[0] != LBR:\n",
    "            raise ValueError(f'Tree starts with {tokens[:4]}')\n",
    "\n",
    "        entity_type = tokens[1]\n",
    "\n",
    "        # ignore invalid subtrees\n",
    "        if entity_type not in [IN, SL]:\n",
    "            return None\n",
    "\n",
    "        entity = entity_type + tokens[2]  # e.g. IN:INTENT\n",
    "\n",
    "        subtrees = []\n",
    "        slot_value_tokens = []\n",
    "\n",
    "        i = 3\n",
    "        while i < len(tokens):\n",
    "            token = tokens[i]\n",
    "\n",
    "            if entity_type == IN and token not in [LBR, RBR]:\n",
    "                i += 1\n",
    "                continue\n",
    "\n",
    "            if token == LBR:\n",
    "                subtree, j = cls.from_tokens(tokens[i:], return_index=True)\n",
    "                subtrees.append(subtree)\n",
    "                i += j\n",
    "                continue\n",
    "\n",
    "            if token == RBR:\n",
    "                if slot_value_tokens:\n",
    "                    subtrees = [Tree(' '.join(slot_value_tokens))]\n",
    "                    slot_value_tokens = []\n",
    "                i += 1\n",
    "                break\n",
    "\n",
    "            if entity_type == SL:\n",
    "                slot_value_tokens.append(token)\n",
    "                i += 1\n",
    "                continue\n",
    "\n",
    "        tree = Tree(entity, subtrees)\n",
    "                \n",
    "        if return_index:\n",
    "            return tree, i\n",
    "\n",
    "        return tree\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_case_1 = {\n",
    "    'input': [LBR, IN, 'INTENT1', 'text', LBR, SL, 'SLOT1', 'slot', 'value', RBR, RBR],\n",
    "    'output': Tree(IN + 'INTENT1', [Tree(SL + 'SLOT1', [Tree('slot value')])])\n",
    "}\n",
    "\n",
    "test_case_2  = {\n",
    "    'input': [LBR, IN, 'INTENT1', 'text', LBR, SL, 'SLOT1', 'slot', 'value', RBR, 'more', 'text', LBR, SL, 'SLOT2', 'slot2', 'value', RBR, RBR],\n",
    "    'output': {IN + 'INTENT1': [{SL + 'SLOT1': [Tree('slot value')]}, {SL + 'SLOT2': [Tree('slot2 value')]}]}\n",
    "}\n",
    "\n",
    "test_case_3  = {\n",
    "    'input': [LBR, IN, 'INTENT1', 'text', LBR, SL, 'SLOT1', 'slot', 'value', RBR, 'more', 'text', LBR, SL, 'SLOT1', 'slot2', 'value', RBR, RBR],\n",
    "    'output': {IN + 'INTENT1': [{SL + 'SLOT1': [Tree('slot value')]}, {SL + 'SLOT1': [Tree('slot2 value')]}]}  # this is why you should use lists and not sets/dicts\n",
    "}\n",
    "\n",
    "test_case_4  = {\n",
    "    'input': [LBR, IN, 'INTENT1', 'text', LBR, SL, 'SLOT1', 'slot', 'value', RBR, 'more', 'text', LBR, SL, 'SLOT1'],\n",
    "    'output': {IN + 'INTENT1': [{SL + 'SLOT1': [Tree('slot value')]}, {SL + 'SLOT1': [Tree('slot2 value')]}]}  # this is why you should use lists and not sets/dicts\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'IN:INTENT1': [{'SL:SLOT1': [{'slot value': []}]}]}\n",
      "3\n",
      "Counter({'IN:INTENT1': 1, 'SL:SLOT1': 1, 'slot value': 1})\n"
     ]
    }
   ],
   "source": [
    "tree = Tree.from_tokens(test_case_1['input'])\n",
    "print(tree)\n",
    "print(len(tree))\n",
    "print(tree.counts)\n",
    "\n",
    "assert tree == test_case_1['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'IN:INTENT1': [{'SL:SLOT1': [{'slot value': []}]}, {'SL:SLOT2': [{'slot2 value': []}]}]}\n",
      "5\n",
      "Counter({'IN:INTENT1': 1, 'SL:SLOT1': 1, 'slot value': 1, 'SL:SLOT2': 1, 'slot2 value': 1})\n"
     ]
    }
   ],
   "source": [
    "tree = Tree.from_tokens(test_case_2['input'])\n",
    "print(tree)\n",
    "print(len(tree))\n",
    "print(tree.counts)\n",
    "\n",
    "assert tree == test_case_2['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'IN:INTENT1': [{'SL:SLOT1': [{'slot value': []}]}, {'SL:SLOT1': [{'slot2 value': []}]}]}\n",
      "5\n",
      "Counter({'SL:SLOT1': 2, 'IN:INTENT1': 1, 'slot value': 1, 'slot2 value': 1})\n"
     ]
    }
   ],
   "source": [
    "tree = Tree.from_tokens(test_case_3['input'])\n",
    "print(tree)\n",
    "print(len(tree))\n",
    "print(tree.counts)\n",
    "\n",
    "assert tree == test_case_3['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'IN:INTENT1': [{'SL:SLOT1': [{'slot value': []}]}, {'SL:SLOT1': []}]}\n",
      "4\n",
      "Counter({'SL:SLOT1': 2, 'IN:INTENT1': 1, 'slot value': 1})\n"
     ]
    }
   ],
   "source": [
    "tree = Tree.from_tokens(test_case_4['input'])\n",
    "print(tree)\n",
    "print(len(tree))\n",
    "print(tree.counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_table('../data/top-dataset-semantic-parsing/eval.tsv', names=['text', 'tokens', 'schema'])\n",
    "\n",
    "tokenized_schema = [TopSchemaTokenizer.tokenize(t) for t in data.schema]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'IN:', 'GET_EVENT', 'Anything', '[', 'SL:', 'DATE_TIME', 'this', 'weekend', ']', 'for', '[', 'SL:', 'ATTRIBUTE_EVENT', 'families', 'with', 'small', 'children', ']', ']']\n",
      "{'IN:GET_EVENT': [{'SL:DATE_TIME': [{'this weekend': []}]}, {'SL:ATTRIBUTE_EVENT': [{'families with small children': []}]}]}\n"
     ]
    }
   ],
   "source": [
    "i = 10\n",
    "\n",
    "print(tokenized_schema[i])\n",
    "print(Tree.from_tokens(tokenized_schema[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'IN:GET_EVENT': [{'SL:CATEGORY_EVENT': [{'Concerts': []}]},\n",
      "                  {'SL:LOCATION': [{'IN:GET_LOCATION': [{'SL:POINT_ON_MAP': [{'Chattaqua Amphitheater': []}]}]}]},\n",
      "                  {'SL:DATE_TIME': [{'this weekend': []}]}]}\n"
     ]
    }
   ],
   "source": [
    "complex_example = (\n",
    "    '[IN:GET_EVENT Are there any '\n",
    "        '[SL:CATEGORY_EVENT Concerts ] at '\n",
    "        '[SL:LOCATION [IN:GET_LOCATION [SL:POINT_ON_MAP Chattaqua Amphitheater ] ] ] '\n",
    "        '[SL:DATE_TIME this weekend ] with available tickets ]'\n",
    ")\n",
    "\n",
    "complex_example_tokens = TopSchemaTokenizer.tokenize(complex_example)\n",
    "complex_tree = Tree.from_tokens(complex_example_tokens)\n",
    "pprint(complex_tree._dict_repr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_case_1 = {\n",
    "    'true': [LBR, IN, 'INTENT1', 'text', LBR, SL, 'SLOT1', 'slot', 'value', RBR, RBR],\n",
    "    'pred': [LBR, IN, 'INTENT1', 'text', LBR, SL, 'SLOT1', 'slot', 'value', RBR, RBR],\n",
    "    'f1': 1,\n",
    "    'precision': 1,\n",
    "    'recall': 1,\n",
    "}\n",
    "\n",
    "test_case_2 = {\n",
    "    'true': [LBR, IN, 'INTENT1', 'text', LBR, SL, 'SLOT1', 'slot', 'value', RBR, RBR],\n",
    "    'pred': [LBR, IN, 'INTENT2', 'text', LBR, SL, 'SLOT1', 'slot', 'value', RBR, RBR],\n",
    "    'f1': 0,\n",
    "    'precision': 0,\n",
    "    'recall': 0,\n",
    "}\n",
    "\n",
    "test_case_3 = {\n",
    "    'true': [LBR, IN, 'INTENT1', 'text', LBR, SL, 'SLOT1', 'slot', 'value', RBR, RBR],\n",
    "    'pred': [LBR, IN, 'INTENT1', 'text', LBR, SL, 'SLOT2', 'slot', 'value', RBR, RBR],\n",
    "    'f1': 0.5,\n",
    "    'precision': 0.5,\n",
    "    'recall': 0.5,\n",
    "}\n",
    "\n",
    "test_case_4 = {\n",
    "    'true': [LBR, IN, 'INTENT1', 'text', LBR, SL, 'SLOT1', 'slot', 'value', RBR, RBR],\n",
    "    'pred': [LBR, IN, 'INTENT1', 'text', LBR, SL, 'SLOT1', 'slot', 'value', RBR, LBR, SL, 'SLOT2', 'value', RBR, RBR],\n",
    "    'f1': 2/3.,\n",
    "    'precision': 3/4.,\n",
    "    'recall': 1,\n",
    "}\n",
    "\n",
    "test_case_5 = {\n",
    "    'true': [LBR, IN, 'INTENT1', 'text', LBR, SL, 'SLOT1', 'slot', 'value', RBR, RBR],\n",
    "    'pred': [LBR, IN, 'INTENT1', 'text', LBR, SL, 'SLOT1', 'slot', 'wrong value', RBR, RBR],\n",
    "    'f1': 2/3.,\n",
    "    'precision': 2/3.,\n",
    "    'recall': 2/3.,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(p, r):\n",
    "    return 2 * p * r / (p + r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'IN:INTENT1': [{'SL:SLOT1': [{'slot value': []}]}]}\n",
      "{'IN:INTENT1': [{'SL:SLOT1': [{'slot value': []}]}]}\n"
     ]
    }
   ],
   "source": [
    "tree1 = Tree.from_tokens(test_case_1['true'])\n",
    "tree2 = Tree.from_tokens(test_case_1['pred'])\n",
    "\n",
    "print(tree1)\n",
    "print(tree2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labeled_bracketing_recall(pred_tokens, true_tokens):\n",
    "    \"\"\"Compute recall labeling bracketng score\"\"\"\n",
    "    pred_tree = Tree.from_tokens(pred_tokens)\n",
    "    true_tree = Tree.from_tokens(true_tokens)\n",
    "\n",
    "    true_positive, false_negative = 0, 0\n",
    "\n",
    "    if pred_tree.entity != true_tree.entity:\n",
    "        false_negative += 1\n",
    "    else:\n",
    "        true_positive += 1\n",
    "        tp, fn = _labeled_bracketing_tp_fn(pred_tree.subtrees, true_tree.subtrees)\n",
    "\n",
    "        true_positive += tp\n",
    "        false_negative += fn\n",
    "    \n",
    "    recall = true_positive / (true_positive + false_negative)\n",
    "    return recall\n",
    "\n",
    "\n",
    "def labeled_bracketing_precision(pred_tokens, true_tokens):\n",
    "    \"\"\"Compute precision labeling bracketng score\"\"\"\n",
    "    pred_tree = Tree.from_tokens(pred_tokens)\n",
    "    true_tree = Tree.from_tokens(true_tokens)\n",
    "\n",
    "    true_positive, false_positive = 0, 0\n",
    "\n",
    "    if pred_tree.entity != true_tree.entity:\n",
    "        false_positive += 1\n",
    "    else:\n",
    "        true_positive += 1\n",
    "        tp, fp = _labeled_bracketing_tp_fp(pred_tree.subtrees, true_tree.subtrees)\n",
    "\n",
    "        true_positive += tp\n",
    "        false_positive += fp\n",
    "\n",
    "    recall = true_positive / (true_positive + false_positive)\n",
    "    return recall\n",
    "\n",
    "\n",
    "def _labeled_bracketing_tp_fn(pred_subtrees: List[Tree], true_subtrees: List[Tree]):\n",
    "    \"\"\"Compute true positive and false negative labeling bracketng scores\"\"\"\n",
    "    true_positive, false_negative = 0, 0\n",
    "\n",
    "    for i, true_tree in enumerate(true_subtrees):\n",
    "        correct_subtree_indices = [i for i, pred_tree in enumerate(pred_subtrees) if pred_tree.entity == true_tree.entity]\n",
    "\n",
    "        if len(correct_subtree_indices) == 0:\n",
    "            false_negative += 1\n",
    "        else:\n",
    "            true_positive += 1\n",
    "            \n",
    "            for pred_subtree_idx in correct_subtree_indices:\n",
    "                pred_tree = pred_subtrees[pred_subtree_idx]\n",
    "                tp, fn = _labeled_bracketing_tp_fn(pred_tree.subtrees, true_tree.subtrees)\n",
    "\n",
    "                true_positive += tp\n",
    "                false_negative += fn            \n",
    "\n",
    "    return true_positive, false_negative\n",
    "\n",
    "\n",
    "def _labeled_bracketing_tp_fp(pred_subtrees: List[Tree], true_subtrees: List[Tree]):\n",
    "    \"\"\"Compute true positive and false positive labeling bracketng scores\"\"\"\n",
    "    return _labeled_bracketing_tp_fn(true_subtrees, pred_subtrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_case_1 passed. Computed recall: 1.0\n",
      "test_case_2 passed. Computed recall: 0.0\n",
      "test_case_3 passed. Computed recall: 0.5\n",
      "test_case_4 passed. Computed recall: 1.0\n",
      "test_case_5 passed. Computed recall: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "test_case = test_case_2\n",
    "\n",
    "for i, test_case in enumerate([test_case_1, test_case_2, test_case_3, test_case_4, test_case_5]):\n",
    "\n",
    "    recall = labeled_bracketing_recall(test_case['pred'], test_case['true'])\n",
    "\n",
    "    if recall == test_case['recall']:\n",
    "        print(f'test_case_{i+1} passed. Computed recall: {recall}')\n",
    "    else:\n",
    "        print(f'\\t test_case_{i+1} FAILED. Computed recall: {recall}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_case_1 passed. Computed precision: 1.0\n",
      "test_case_2 passed. Computed precision: 0.0\n",
      "test_case_3 passed. Computed precision: 0.5\n",
      "test_case_4 passed. Computed precision: 0.75\n",
      "test_case_5 passed. Computed precision: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "for i, test_case in enumerate([test_case_1, test_case_2, test_case_3, test_case_4, test_case_5]):\n",
    "\n",
    "    precision = labeled_bracketing_precision(test_case['pred'], test_case['true'])\n",
    "\n",
    "    if precision == test_case['precision']:\n",
    "        print(f'test_case_{i+1} passed. Computed precision: {precision}')\n",
    "    else:\n",
    "        print(f'\\t test_case_{i+1} FAILED. Computed precision: {precision}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare with the official TOP evaluation tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_table('../data/top-dataset-semantic-parsing/test.tsv', names=['text', 'tokens', 'schema'])\n",
    "data_pred = pd.read_table('../lightning_out/jul8_20epochs_small/predictions.tsv', names=['schema'])\n",
    "\n",
    "tokenized_schema_test = [TopSchemaTokenizer.tokenize(t) for t in data_test.schema]\n",
    "tokenized_schema_pred = [TopSchemaTokenizer.tokenize(t) for t in data_pred.schema]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instance_count': 9042,\n",
       " 'exact_match': 0.25481088254810885,\n",
       " 'labeled_bracketing_scores': {'precision': 0.6032053706505295,\n",
       "  'recall': 0.3814007712312797,\n",
       "  'f1': 0.46731984250526504},\n",
       " 'tree_labeled_bracketing_scores': {'precision': 0.3943362329803328,\n",
       "  'recall': 0.24933488775296686,\n",
       "  'f1': 0.30550315905136893},\n",
       " 'tree_validity': 0.9382879893828799}"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TOP script gives the following metrics\n",
    "\n",
    "{'instance_count': 9042,\n",
    " 'exact_match': 0.25481088254810885,\n",
    " 'labeled_bracketing_scores': {\n",
    "     'precision': 0.6032053706505295,\n",
    "     'recall': 0.3814007712312797,\n",
    "     'f1': 0.46731984250526504\n",
    " },\n",
    " 'tree_labeled_bracketing_scores': {\n",
    "     'precision': 0.3943362329803328,\n",
    "     'recall': 0.24933488775296686,\n",
    "     'f1': 0.30550315905136893\n",
    " },\n",
    " 'tree_validity': 0.9382879893828799}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions = []\n",
    "recalls = []\n",
    "exact_match = 0\n",
    "\n",
    "for pred, true in zip(tokenized_schema_pred, tokenized_schema_test):    \n",
    "    pred_tree = Tree.from_tokens(pred)\n",
    "    true_tree = Tree.from_tokens(true)\n",
    "\n",
    "    if pred_tree == true_tree:\n",
    "        exact_match += 1\n",
    "    \n",
    "    precision = labeled_bracketing_precision(pred, true)\n",
    "    recall = labeled_bracketing_recall(pred, true)\n",
    "    \n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'IN:', 'GET_INFO_TRAFFIC', 'is', 'traffic', 'moving', 'on', '[', 'SL:', 'LOCATION', 'I', '-', '65', ']', ']']\n",
      "{'IN:GET_INFO_TRAFFIC': [{'SL:LOCATION': [{'I - 65': []}]}]}\n"
     ]
    }
   ],
   "source": [
    "print(true)\n",
    "print(true_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.640802521534121\n",
      "Recall   :  0.5737675240412504\n",
      "F1       :  0.6054351126465458\n",
      "exact_match:  0.2591240875912409\n"
     ]
    }
   ],
   "source": [
    "mean_precision = sum(precisions) / len(precisions)\n",
    "mean_recall = sum(recalls) / len(recalls)\n",
    "exact_match /= len(precisions)\n",
    "\n",
    "print('Precision: ', mean_precision)\n",
    "print('Recall   : ', mean_recall)\n",
    "print('F1       : ', f1(mean_precision, mean_recall))\n",
    "print('exact_match: ', exact_match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_bracketing_scores(pred_trees, true_trees):\n",
    "    true_positives = 0\n",
    "    n_predicted = 0\n",
    "    n_expected = 0\n",
    "    \n",
    "    for pred_tree, true_tree in zip(pred_trees, true_trees):\n",
    "        n_predicted += len(pred_tree)\n",
    "        n_expected += len(true_tree)\n",
    "\n",
    "        if pred_tree.entity == true_tree.entity:\n",
    "            true_positives += 1 + _tree_true_positive(pred_tree.subtrees, true_tree.subtrees)\n",
    "\n",
    "    precision = true_positives / n_predicted\n",
    "    recall = true_positives / n_expected\n",
    "\n",
    "    f1 = 0\n",
    "    if precision + recall > 0:\n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    return {'LBS_precision': precision, 'LBS_recall': recall, 'LBS_F1': f1}\n",
    "\n",
    "\n",
    "def _tree_true_positive(pred_subtrees, true_subtrees):\n",
    "    true_positive = 0\n",
    "\n",
    "    for i, true_tree in enumerate(true_subtrees):\n",
    "        correct_subtree_indices = [i for i, pred_tree in enumerate(pred_subtrees) if pred_tree.entity == true_tree.entity]\n",
    "\n",
    "        if len(correct_subtree_indices) == 0:\n",
    "            continue\n",
    "        \n",
    "        true_positive += 1\n",
    "            \n",
    "        for pred_subtree_idx in correct_subtree_indices:\n",
    "            pred_tree = pred_subtrees[pred_subtree_idx]\n",
    "        \n",
    "            tp = _tree_true_positive(pred_tree.subtrees, true_tree.subtrees)\n",
    "            true_positive += tp\n",
    "        \n",
    "    return true_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_case_1:\n",
      "{'LBS_precision': 1.0, 'LBS_recall': 1.0, 'LBS_F1': 1.0}\n",
      "\n",
      "test_case_2:\n",
      "{'LBS_precision': 0.0, 'LBS_recall': 0.0, 'LBS_F1': 0}\n",
      "\n",
      "test_case_3:\n",
      "{'LBS_precision': 0.3333333333333333, 'LBS_recall': 0.3333333333333333, 'LBS_F1': 0.3333333333333333}\n",
      "\n",
      "test_case_4:\n",
      "{'LBS_precision': 0.6, 'LBS_recall': 1.0, 'LBS_F1': 0.7499999999999999}\n",
      "\n",
      "test_case_5:\n",
      "{'LBS_precision': 0.6666666666666666, 'LBS_recall': 0.6666666666666666, 'LBS_F1': 0.6666666666666666}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, test_case in enumerate([test_case_1, test_case_2, test_case_3, test_case_4, test_case_5]):\n",
    "\n",
    "    tree_true = Tree.from_tokens(test_case['true'])\n",
    "    tree_pred = Tree.from_tokens(test_case['pred'])\n",
    "\n",
    "    metrics = label_bracketing_scores([tree_pred], [tree_true])\n",
    "\n",
    "    print(f'test_case_{i+1}:')\n",
    "    print(metrics)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LBS_precision': 0.6405084598194851, 'LBS_recall': 0.441435314825186, 'LBS_F1': 0.5226575728511716}\n"
     ]
    }
   ],
   "source": [
    "pred_trees = [Tree.from_tokens(t) for t in tokenized_schema_pred]\n",
    "true_trees = [Tree.from_tokens(t) for t in tokenized_schema_test]\n",
    "\n",
    "metrics = label_bracketing_scores(pred_trees, true_trees)\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still a bit higher then the official implementation {'precision': 0.603, 'recall': 0.381, 'f1': 0.467},"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Per-class scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_bracketing_scores_for_classes(pred_trees, true_trees, classes):\n",
    "    \"\"\"Compute label bracketing scores only considering slots, intents and values from classes.\"\"\"\n",
    "    true_positives = 0\n",
    "    n_predicted = 0\n",
    "    n_expected = 0\n",
    "\n",
    "    for pred_tree, true_tree in zip(pred_trees, true_trees):\n",
    "        n_predicted += len(pred_tree)\n",
    "        n_expected += len(true_tree)\n",
    "\n",
    "        if pred_tree.entity == true_tree.entity:\n",
    "            true_positives += 1 + _tree_true_positive(pred_tree.subtrees, true_tree.subtrees)\n",
    "\n",
    "    precision = 0 if n_predicted == 0 else true_positives / n_predicted\n",
    "    recall = 0 if n_expected == 0 else true_positives / n_expected\n",
    "\n",
    "    f1 = 0\n",
    "    if precision + recall > 0:\n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "    return {'cLBS_precision': precision, 'cLBS_recall': recall, 'cLBS_F1': f1}\n",
    "\n",
    "\n",
    "def _tree_true_positive_for_classes(pred_subtrees, true_subtrees, classes):\n",
    "    true_positive = 0\n",
    "    \n",
    "    for i, true_tree in enumerate(true_subtrees):\n",
    "\n",
    "        correct_subtree_indices = [i for i, pred_tree in enumerate(pred_subtrees) if pred_tree.entity == true_tree.entity]\n",
    "\n",
    "        if len(correct_subtree_indices) == 0:\n",
    "            continue\n",
    "        \n",
    "        if true_tree.entity in classes:\n",
    "            true_positive += 1\n",
    "            \n",
    "        for pred_subtree_idx in correct_subtree_indices:\n",
    "            pred_tree = pred_subtrees[pred_subtree_idx]\n",
    "        \n",
    "            tp = _tree_true_positive_for_classes(pred_tree.subtrees, true_tree.subtrees, classes)\n",
    "            true_positive += tp\n",
    "        \n",
    "    return true_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_trees = [Tree.from_tokens(t) for ]\n",
    "\n",
    "for i, test_case in enumerate([test_case_1, test_case_2, test_case_3, test_case_4, test_case_5]):\n",
    "\n",
    "    tree_true = Tree.from_tokens(test_case['true'])\n",
    "    tree_pred = Tree.from_tokens(test_case['pred'])\n",
    "\n",
    "    metrics = label_bracketing_scores([tree_pred], [tree_true])\n",
    "\n",
    "    print(f'test_case_{i+1}:')\n",
    "    print(metrics)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree path score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
